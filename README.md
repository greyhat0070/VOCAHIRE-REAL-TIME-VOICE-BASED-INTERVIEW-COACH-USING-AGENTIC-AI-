# ğŸ§  VocaHire â€“ Terminal-Based Voice Interview Simulator

**VocaHire** is a terminal-based voice-interactive interview agent that simulates a professional interview experience using real-time audio input, AI-powered agents, and feedback mechanisms.

---

## ğŸš€ Features

- ğŸ™ï¸ Voice Activity Detection (VAD) for real-time recording
- ğŸ§¾ Resume-based question generation
- ğŸ¤– Modular agent architecture (general, resume, fallback, feedback)
- ğŸ§  Tone analysis and STT via local Whisper
- ğŸ—£ï¸ Text-to-speech feedback
- ğŸ“¦ Audio recording storage and logging

---

## ğŸ§± Tech Stack

| Layer           | Tools Used                         |
|------------------|-------------------------------------|
| Language         | Python 3.11+                        |
| Audio Processing | `webrtcvad`, `pyaudio`, `pydub`     |
| STT              | OpenAI's `whisper` (local)          |
| TTS              | `pyttsx3`, `gtts`                   |
| PDF Parsing      | `PyMuPDF (fitz)`                    |
| AI Logic         | Modular agents (`interview_agent.py`, `resume_qa_generator.py`, etc.) |
| Logging & Data   | JSON, `.wav` recordings             |
| LLM Integration  | Claude 3 Haiku via OpenRouter API, Flan-T5 |
---



## ğŸ“ Project Structure

vocahire/
â”œâ”€â”€ agents/ # Core agent modules
â”‚ â”œâ”€â”€ interview_agent.py
â”‚ â”œâ”€â”€ resume_qa_generator.py
â”‚ â”œâ”€â”€ feedback_engine.py
â”‚ â””â”€â”€ ...
â”‚
â”œâ”€â”€ audio/ # Audio processing pipeline
â”‚ â”œâ”€â”€ step2_vad_listener.py
â”‚ â”œâ”€â”€ stt_whisper_local.py
â”‚ â”œâ”€â”€ tone_analysis.py
â”‚ â”œâ”€â”€ tts_speaker.py
â”‚ â””â”€â”€ step4_voice_to_langgraph.py
â”‚
â”œâ”€â”€ data/ # Logs, parsed resumes, audio recordings
â”‚ â”œâ”€â”€ parsed_resume.json
â”‚ â””â”€â”€ recordings/
â”‚
â”œâ”€â”€ main.py # Entry-point for running the system
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env



---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/vocahire.git
cd vocahire


2. Create a Virtual Environment (Recommended)
python -m venv .venv
.venv\Scripts\activate    # Windows

3. Install Required Packages
pip install -r requirements.txt

You may also need to install ffmpeg for audio processing and Whisper dependencies.

4. Run the Interview Script

python audio/step4_voice_to_langgraph.py





##ğŸ”ŠAudio Notes 
Audio recordings are saved in data/recordings/.

Logs and parsed resume data are stored in the data/ directory.

Whisper (for speech-to-text) is run locally â€” no OpenAI API needed.





##ğŸ§  Agent Details
resume_qa_generator.py â€“ Questions based on uploaded resume.

general_qa_generator.py â€“ Common behavioral questions.

feedback_engine.py â€“ Evaluates tone, fluency, and relevance.

fallback_qa_generator.py â€“ Used when others donâ€™t respond.

interview_agent.py â€“ Main orchestration agent.





##âœ… Future Enhancements
Integrate Streamlit or CLI-based menu

PDF export of feedback

Role-based interview templates

Real-time emotion/tone classification





ğŸ‘¨â€ğŸ’» Developed by
  KOMMANA GOWTHAM 
  DAGGUMELLI SRISANTH 
  GOMPA VASAVI
